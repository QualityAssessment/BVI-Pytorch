{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f00235-8017-42f5-9122-576188ae2609",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import argparse\n",
    "import pickle as pkl\n",
    "import random\n",
    "\n",
    "import open_clip\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import yaml\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "from scipy.stats import kendalltau as kendallr\n",
    "from tqdm import tqdm\n",
    "\n",
    "from buona_vista import datasets\n",
    "\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cefbf3b3-4a57-4ec8-95c0-7d67025945ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rescale(x):\n",
    "    x = np.array(x)\n",
    "    print(\"Mean:\", x.mean(), \"Std\", x.std())\n",
    "    x = (x - x.mean()) / x.std()\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e4898-0627-47e7-a3db-c06385842617",
   "metadata": {},
   "outputs": [],
   "source": [
    "    with open(\"buona_vista_sa_index.yml\", \"r\") as f:\n",
    "        opt = yaml.safe_load(f)   \n",
    "    \n",
    "    val_datasets = {}\n",
    "    for name, dataset in opt[\"data\"].items():\n",
    "        val_datasets[name] = getattr(datasets, dataset[\"type\"])(dataset[\"args\"])\n",
    "\n",
    "    print(open_clip.list_pretrained())\n",
    "    model, _, _ = open_clip.create_model_and_transforms(\"RN50\",pretrained=\"openai\")\n",
    "    model = model.to(\"cuda\")\n",
    "    print(\"loading succeed\")\n",
    "\n",
    "    texts = [\n",
    "        \"high quality\",\n",
    "        \"low quality\",\n",
    "        \"a good photo\",\n",
    "        \"a bad photo\",\n",
    "    ]\n",
    "    tokenizer = open_clip.get_tokenizer(\"RN50\")\n",
    "    text_tokens = tokenizer(texts).to(\"cuda\")\n",
    "    print(f\"Prompt_loading_succeed, {texts}\")\n",
    "\n",
    "    results = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35e2a7d-1a27-44ba-830a-331f293d886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gts, paths = {}, {}\n",
    "\n",
    "for val_name, val_dataset in val_datasets.items():\n",
    "    gts[val_name] = [val_dataset.video_infos[i][\"label\"] for i in range(len(val_dataset))]\n",
    "    \n",
    "for val_name, val_dataset in val_datasets.items():\n",
    "    paths[val_name] = [val_dataset.video_infos[i][\"filename\"] for i in range(len(val_dataset))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ef7272f-6fd6-4bc2-a17b-d37a33651b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not glob.glob(\"CLIP_vis_features.pt\"):\n",
    "    visual_features = get_features(False)\n",
    "visual_features = torch.load(\"CLIP_vis_features.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83963948-5aa5-426d-8d5d-5c2d59db0de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "def encode_text_prompts(prompts):\n",
    "    text_tokens = tokenizer(prompts).to(\"cuda\")\n",
    "    with torch.no_grad():\n",
    "        embedding = model.token_embedding(text_tokens)\n",
    "        text_features = model.encode_text(text_tokens).float().cpu()\n",
    "    return text_tokens.cpu(), embedding.cpu(), text_features\n",
    "    \n",
    "text_tokens, embedding, text_feats = encode_text_prompts(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67af5c4e-f77b-4713-b30e-cbf320a95baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo_features.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f80a8a5-b7ee-4eeb-a610-790f888479cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "backend = \"Matlab\" # Matlab | Pytorch\n",
    "\n",
    "if backend == \"Matlab\":\n",
    "    with open(\"naturalnesses_matlab_results.pkl\",\"rb\") as f:\n",
    "        matlab_results = pkl.load(f)\n",
    "        sn = matlab_results[\"spatial\"]\n",
    "        tn2 = matlab_results[\"temporal\"]\n",
    "\n",
    "else:\n",
    "    sn, tn2 = {}, {}\n",
    "    for val_name in visual_features:\n",
    "        with open(f\"spatial_naturalness_{val_name}.pkl\",\"rb\") as infile:\n",
    "            sn[val_name] = pkl.load(infile)[\"pr_labels\"]\n",
    "\n",
    "        with open(\"temporal_naturalness_pubs.pkl\",\"rb\") as infile:\n",
    "            tn = pkl.load(infile)\n",
    "\n",
    "        tn2[val_name] = tn[f\"{val_name}\"][\"tn_index\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0ebd8ee-70c4-4c88-bf92-49b594828328",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d5d908-7cec-4a31-b4d3-10b0a4121fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "prs  = {}\n",
    "local_prs = {}\n",
    "for val_name in visual_features:\n",
    "    prs[val_name] = []\n",
    "    local_prs[val_name] = [[],[],[],[]]\n",
    "    for feat in tqdm(visual_features[val_name]):\n",
    "        with torch.no_grad():\n",
    "            logits = feat @ text_feats.T.cpu()\n",
    "        logits = logits.cpu().numpy()\n",
    "        semantic_affinity_index = np.zeros((50,64))\n",
    "        for k in [0,1]:\n",
    "            pn_pair = torch.from_numpy(logits[..., 2 * k : 2 * k + 2]).float().numpy()\n",
    "            semantic_affinity_index += pn_pair[...,0] - pn_pair[...,1]\n",
    "        \n",
    "        prs[val_name].append(semantic_affinity_index[1:].mean())\n",
    "        #local_prs[val_name][0].append(semantic_affinity_index[1:].reshape(64,7,7))\n",
    "        \n",
    "\n",
    "            \n",
    "            \n",
    "    prs[val_name] = rescale(prs[val_name])\n",
    "    if val_name == 'val-maxwell':\n",
    "        for key in d:\n",
    "            try:\n",
    "                print(key, val_name, \"P\", pearsonr(prs[val_name], d[key])[0])\n",
    "            except:\n",
    "                print(key)\n",
    "    print(\"sa_only\", val_name, \"S\", spearmanr(prs[val_name], gts[val_name])[0], \"P\", pearsonr(prs[val_name], gts[val_name])[0])\n",
    "    #prs += sn[val_name] #+ tn2[val_name]\n",
    "    #print(\"all_indices\", val_name, \"S\", spearmanr(prs, gts[val_name])[0], \"P\", pearsonr(prs, gts[val_name])[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e982b8-e732-4318-b75e-2e7a77d667c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_name in visual_features:\n",
    "    if val_name == \"val-ytugc\":\n",
    "        sn[val_name] = np.zeros(1147)\n",
    "        tn2[val_name] = np.zeros(1147)\n",
    "    all_prs =  prs[val_name] + sn[val_name] + tn2[val_name]\n",
    "    print(\"sa_only\", val_name, \"S\", spearmanr(prs[val_name], gts[val_name])[0], \"P\", pearsonr(prs[val_name], gts[val_name])[0])\n",
    "    print(\"sn_only\", val_name, \"S\", spearmanr(sn[val_name], gts[val_name])[0], \"P\", pearsonr(sn[val_name], gts[val_name])[0])\n",
    "    print(\"tn_only\", val_name, \"S\", spearmanr(tn2[val_name], gts[val_name])[0], \"P\", pearsonr(tn2[val_name], gts[val_name])[0])\n",
    "    print(\"all_indices\", val_name, \"S\", spearmanr(all_prs, gts[val_name])[0], \"P\", pearsonr(all_prs, gts[val_name])[0])\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7ec721-498a-4ae9-a46e-127e69e5d5ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "for val_name in visual_features:\n",
    "    for i in range(4):\n",
    "        local_prs[val_name][i] = rescale(np.stack(local_prs[val_name][i], 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "id": "803cdae7-d7ff-488f-9ad0-2f45c591d930",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "from torch.nn.functional import interpolate\n",
    "\n",
    "def visualize_local_quality(video_path, quality_map_tensors, output_path):\n",
    "    cap = cv2.VideoCapture(video_path)\n",
    "    old_width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "    old_height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "    width = 480\n",
    "    height = int(480 * old_height / old_width)\n",
    "    frame_cnt = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    fps = int(cap.get(cv2.CAP_PROP_FPS))\n",
    "    resized_quality_maps = []\n",
    "    for quality_map_tensor in quality_map_tensors:\n",
    "        resized_quality_maps += [interpolate(quality_map_tensor[None, None, :], size=(frame_cnt, height, width), mode=\"nearest\").numpy()[0,0]]\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, 5*height))\n",
    "\n",
    "    frame_idx = 0\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        frame = cv2.resize(frame, (width, height))\n",
    "        original_frame = frame\n",
    "        for resized_quality_map in resized_quality_maps:\n",
    "            resized_quality_map = resized_quality_map[frame_idx]\n",
    "\n",
    "            #quality_map = quality_map_tensor[frame_idx].numpy()\n",
    "            #resized_quality_map = cv2.resize(quality_map, (width, height), interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "            color_map = np.zeros((height, width, 3), dtype=np.uint8)\n",
    "            color_map[:, :, 2] = (1 - resized_quality_map) * 255  # Red channel\n",
    "            color_map[:, :, 1] = resized_quality_map * 255  # Green channel\n",
    "\n",
    "            alpha = 0.5\n",
    "            blended_frame = cv2.addWeighted(original_frame, alpha, color_map, 1 - alpha, 0)\n",
    "            frame = np.concatenate((frame, blended_frame), 0)\n",
    "        out.write(frame)\n",
    "        frame_idx += 1\n",
    "\n",
    "    cap.release()\n",
    "    out.release()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74fa69cf-b2e0-46b8-adcd-7ca321722bd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_Debug",
   "language": "python",
   "name": "pt1.8v"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
